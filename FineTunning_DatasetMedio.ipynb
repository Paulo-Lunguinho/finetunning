{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import json\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(filename, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"JSON carregado! Total de itens: {len(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "7XAnklyEwMsm",
        "outputId": "1bc0231e-d409-4582-bfd1-2997e103a33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f34c4a09-8680-4fa2-b9b7-1ef6f32dfa59\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f34c4a09-8680-4fa2-b9b7-1ef6f32dfa59\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_shuffle.json to data_shuffle.json\n",
            "JSON carregado! Total de itens: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Formatação das entradas"
      ],
      "metadata": {
        "id": "dOG-B6upwxju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_uJrJlrk--D"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "    desired_response = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "    return instruction_text + input_text + desired_response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_input(data[50]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vD7GA0kvypX",
        "outputId": "21b665ff-d495-49d1-e88c-b67bef6fd9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "\"Please distill the main ideas and key information from the provided text into a concise and coherent overview.\"\n",
            "\n",
            "### Input:\n",
            "(CNN) -- A Marine convicted for his role in the death of an Iraqi civilian was sentenced Friday to a reduction in rank and will be discharged. Cpl. Trent D. Thomas was found guilty Wednesday of kidnapping and conspiracy to commit several offenses -- including murder, larceny, housebreaking, kidnapping, and making false official statements -- for his involvement in the April 2006 death in Hamdaniya, Iraq. Thomas will be demoted to the rank of entry-level private and will receive a bad-conduct discharge. The 25-year-old was among seven Marines and a Navy medic who were charged in connection with the death of Hashim Ibrahim Awad, 52. The Marines accused in the case were members of Kilo Company, 3rd Battalion, 5th Marine Regiment. They reported at the time that Awad planned to detonate a roadside bomb targeting their patrol. But several residents of Hamdaniya, including relatives of the victim, gave a different account, prompting a criminal investigation. Prosecutors accuse the group's squad leader, Sgt. Lawrence G. Hutchins III, of dragging Awad from his home, shooting him in the street and then making it look like he had planned to ambush American troops. Hutchins has pleaded not guilty to murder, conspiracy and other charges in the case. He faces a sentence of life in prison if convicted. Thomas changed his plea from guilty to not guilty in February, arguing that he had merely followed orders. He told his attorneys that after reviewing the evidence against him, he realized \"that what happened overseas happened as a result of obedience to orders, and he hasn't done anything wrong,\" defense attorney Victor Kelley said. Thomas said in January, shortly after entering his guilty plea, that he was \"truly sorry\" for his role in the killing. He could have been sentenced to life in prison under his original plea. E-mail to a friend .\n",
            "\n",
            "### Response:\n",
            "Cpl. Trent D. Thomas found guilty this week of conspiracy to commit murder .\n",
            "Marine gets rank of private, will be discharged for role in death of Iraqi civilian .\n",
            "Group's leader awaits trial on murder and conspiracy charges .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split"
      ],
      "metadata": {
        "id": "eAdJJprYw2oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.8)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:(train_portion + test_portion)]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUEtdl_Nwo_N",
        "outputId": "db1f081f-7214-4f3c-c229-153ff0af8e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Dataset"
      ],
      "metadata": {
        "id": "P9pR_d4F4NDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "OvHIZkyc0OSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom Collate Function"
      ],
      "metadata": {
        "id": "inJ6nVjz4QdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "PwOoPI_21RBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_fn(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGs1NEvI1ZpT",
        "outputId": "20258aef-44a8-4dfe-fe1d-b21a5800d281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]]), tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Choose Device\n"
      ],
      "metadata": {
        "id": "WFuqngDP4F6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    # Use PyTorch 2.9 or newer for stable mps results\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsnwnpIS29WV",
        "outputId": "021a09b6-b104-4e10-b633-f6050d413606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "H7SYrAGM3h4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataLoaders"
      ],
      "metadata": {
        "id": "sgRsU4-Z4BcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 1\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "jgFe-z0s3nrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjStogKT4vBy",
        "outputId": "9b9538b1-e79d-46ed-ba7d-61fad64fd89a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([1, 451]) torch.Size([1, 451])\n",
            "torch.Size([1, 753]) torch.Size([1, 753])\n",
            "torch.Size([1, 214]) torch.Size([1, 214])\n",
            "torch.Size([1, 254]) torch.Size([1, 254])\n",
            "torch.Size([1, 565]) torch.Size([1, 565])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 659]) torch.Size([1, 659])\n",
            "torch.Size([1, 428]) torch.Size([1, 428])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 110]) torch.Size([1, 110])\n",
            "torch.Size([1, 868]) torch.Size([1, 868])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 865]) torch.Size([1, 865])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 974]) torch.Size([1, 974])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 248]) torch.Size([1, 248])\n",
            "torch.Size([1, 201]) torch.Size([1, 201])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 173]) torch.Size([1, 173])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 890]) torch.Size([1, 890])\n",
            "torch.Size([1, 992]) torch.Size([1, 992])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 108]) torch.Size([1, 108])\n",
            "torch.Size([1, 104]) torch.Size([1, 104])\n",
            "torch.Size([1, 143]) torch.Size([1, 143])\n",
            "torch.Size([1, 772]) torch.Size([1, 772])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 150]) torch.Size([1, 150])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 198]) torch.Size([1, 198])\n",
            "torch.Size([1, 111]) torch.Size([1, 111])\n",
            "torch.Size([1, 381]) torch.Size([1, 381])\n",
            "torch.Size([1, 109]) torch.Size([1, 109])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 135]) torch.Size([1, 135])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 126]) torch.Size([1, 126])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 136]) torch.Size([1, 136])\n",
            "torch.Size([1, 199]) torch.Size([1, 199])\n",
            "torch.Size([1, 247]) torch.Size([1, 247])\n",
            "torch.Size([1, 945]) torch.Size([1, 945])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 251]) torch.Size([1, 251])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 318]) torch.Size([1, 318])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 751]) torch.Size([1, 751])\n",
            "torch.Size([1, 337]) torch.Size([1, 337])\n",
            "torch.Size([1, 971]) torch.Size([1, 971])\n",
            "torch.Size([1, 98]) torch.Size([1, 98])\n",
            "torch.Size([1, 78]) torch.Size([1, 78])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 189]) torch.Size([1, 189])\n",
            "torch.Size([1, 121]) torch.Size([1, 121])\n",
            "torch.Size([1, 156]) torch.Size([1, 156])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 154]) torch.Size([1, 154])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 154]) torch.Size([1, 154])\n",
            "torch.Size([1, 113]) torch.Size([1, 113])\n",
            "torch.Size([1, 123]) torch.Size([1, 123])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 126]) torch.Size([1, 126])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 112]) torch.Size([1, 112])\n",
            "torch.Size([1, 240]) torch.Size([1, 240])\n",
            "torch.Size([1, 211]) torch.Size([1, 211])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 109]) torch.Size([1, 109])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 103]) torch.Size([1, 103])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 676]) torch.Size([1, 676])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 456]) torch.Size([1, 456])\n",
            "torch.Size([1, 207]) torch.Size([1, 207])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 577]) torch.Size([1, 577])\n",
            "torch.Size([1, 273]) torch.Size([1, 273])\n",
            "torch.Size([1, 213]) torch.Size([1, 213])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 244]) torch.Size([1, 244])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 134]) torch.Size([1, 134])\n",
            "torch.Size([1, 241]) torch.Size([1, 241])\n",
            "torch.Size([1, 158]) torch.Size([1, 158])\n",
            "torch.Size([1, 345]) torch.Size([1, 345])\n",
            "torch.Size([1, 114]) torch.Size([1, 114])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 615]) torch.Size([1, 615])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 186]) torch.Size([1, 186])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 218]) torch.Size([1, 218])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 156]) torch.Size([1, 156])\n",
            "torch.Size([1, 104]) torch.Size([1, 104])\n",
            "torch.Size([1, 278]) torch.Size([1, 278])\n",
            "torch.Size([1, 121]) torch.Size([1, 121])\n",
            "torch.Size([1, 112]) torch.Size([1, 112])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 212]) torch.Size([1, 212])\n",
            "torch.Size([1, 108]) torch.Size([1, 108])\n",
            "torch.Size([1, 578]) torch.Size([1, 578])\n",
            "torch.Size([1, 149]) torch.Size([1, 149])\n",
            "torch.Size([1, 236]) torch.Size([1, 236])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 191]) torch.Size([1, 191])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 149]) torch.Size([1, 149])\n",
            "torch.Size([1, 298]) torch.Size([1, 298])\n",
            "torch.Size([1, 244]) torch.Size([1, 244])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 891]) torch.Size([1, 891])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 765]) torch.Size([1, 765])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 326]) torch.Size([1, 326])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 111]) torch.Size([1, 111])\n",
            "torch.Size([1, 247]) torch.Size([1, 247])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 192]) torch.Size([1, 192])\n",
            "torch.Size([1, 117]) torch.Size([1, 117])\n",
            "torch.Size([1, 159]) torch.Size([1, 159])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 257]) torch.Size([1, 257])\n",
            "torch.Size([1, 341]) torch.Size([1, 341])\n",
            "torch.Size([1, 920]) torch.Size([1, 920])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 448]) torch.Size([1, 448])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 365]) torch.Size([1, 365])\n",
            "torch.Size([1, 223]) torch.Size([1, 223])\n",
            "torch.Size([1, 203]) torch.Size([1, 203])\n",
            "torch.Size([1, 544]) torch.Size([1, 544])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 948]) torch.Size([1, 948])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 700]) torch.Size([1, 700])\n",
            "torch.Size([1, 105]) torch.Size([1, 105])\n",
            "torch.Size([1, 214]) torch.Size([1, 214])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 708]) torch.Size([1, 708])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 321]) torch.Size([1, 321])\n",
            "torch.Size([1, 224]) torch.Size([1, 224])\n",
            "torch.Size([1, 199]) torch.Size([1, 199])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 346]) torch.Size([1, 346])\n",
            "torch.Size([1, 132]) torch.Size([1, 132])\n",
            "torch.Size([1, 124]) torch.Size([1, 124])\n",
            "torch.Size([1, 251]) torch.Size([1, 251])\n",
            "torch.Size([1, 689]) torch.Size([1, 689])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 189]) torch.Size([1, 189])\n",
            "torch.Size([1, 130]) torch.Size([1, 130])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 105]) torch.Size([1, 105])\n",
            "torch.Size([1, 575]) torch.Size([1, 575])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 178]) torch.Size([1, 178])\n",
            "torch.Size([1, 117]) torch.Size([1, 117])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 726]) torch.Size([1, 726])\n",
            "torch.Size([1, 247]) torch.Size([1, 247])\n",
            "torch.Size([1, 547]) torch.Size([1, 547])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 712]) torch.Size([1, 712])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 288]) torch.Size([1, 288])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 857]) torch.Size([1, 857])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 164]) torch.Size([1, 164])\n",
            "torch.Size([1, 202]) torch.Size([1, 202])\n",
            "torch.Size([1, 224]) torch.Size([1, 224])\n",
            "torch.Size([1, 344]) torch.Size([1, 344])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 814]) torch.Size([1, 814])\n",
            "torch.Size([1, 388]) torch.Size([1, 388])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 513]) torch.Size([1, 513])\n",
            "torch.Size([1, 336]) torch.Size([1, 336])\n",
            "torch.Size([1, 623]) torch.Size([1, 623])\n",
            "torch.Size([1, 133]) torch.Size([1, 133])\n",
            "torch.Size([1, 291]) torch.Size([1, 291])\n",
            "torch.Size([1, 208]) torch.Size([1, 208])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 823]) torch.Size([1, 823])\n",
            "torch.Size([1, 351]) torch.Size([1, 351])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 436]) torch.Size([1, 436])\n",
            "torch.Size([1, 931]) torch.Size([1, 931])\n",
            "torch.Size([1, 105]) torch.Size([1, 105])\n",
            "torch.Size([1, 224]) torch.Size([1, 224])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 421]) torch.Size([1, 421])\n",
            "torch.Size([1, 120]) torch.Size([1, 120])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 229]) torch.Size([1, 229])\n",
            "torch.Size([1, 783]) torch.Size([1, 783])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 495]) torch.Size([1, 495])\n",
            "torch.Size([1, 272]) torch.Size([1, 272])\n",
            "torch.Size([1, 249]) torch.Size([1, 249])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 433]) torch.Size([1, 433])\n",
            "torch.Size([1, 258]) torch.Size([1, 258])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 248]) torch.Size([1, 248])\n",
            "torch.Size([1, 189]) torch.Size([1, 189])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 364]) torch.Size([1, 364])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 188]) torch.Size([1, 188])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 279]) torch.Size([1, 279])\n",
            "torch.Size([1, 496]) torch.Size([1, 496])\n",
            "torch.Size([1, 84]) torch.Size([1, 84])\n",
            "torch.Size([1, 321]) torch.Size([1, 321])\n",
            "torch.Size([1, 218]) torch.Size([1, 218])\n",
            "torch.Size([1, 393]) torch.Size([1, 393])\n",
            "torch.Size([1, 454]) torch.Size([1, 454])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 835]) torch.Size([1, 835])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 678]) torch.Size([1, 678])\n",
            "torch.Size([1, 215]) torch.Size([1, 215])\n",
            "torch.Size([1, 161]) torch.Size([1, 161])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 176]) torch.Size([1, 176])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 818]) torch.Size([1, 818])\n",
            "torch.Size([1, 605]) torch.Size([1, 605])\n",
            "torch.Size([1, 588]) torch.Size([1, 588])\n",
            "torch.Size([1, 740]) torch.Size([1, 740])\n",
            "torch.Size([1, 318]) torch.Size([1, 318])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 164]) torch.Size([1, 164])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 351]) torch.Size([1, 351])\n",
            "torch.Size([1, 110]) torch.Size([1, 110])\n",
            "torch.Size([1, 240]) torch.Size([1, 240])\n",
            "torch.Size([1, 127]) torch.Size([1, 127])\n",
            "torch.Size([1, 103]) torch.Size([1, 103])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 77]) torch.Size([1, 77])\n",
            "torch.Size([1, 109]) torch.Size([1, 109])\n",
            "torch.Size([1, 502]) torch.Size([1, 502])\n",
            "torch.Size([1, 919]) torch.Size([1, 919])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 285]) torch.Size([1, 285])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 132]) torch.Size([1, 132])\n",
            "torch.Size([1, 355]) torch.Size([1, 355])\n",
            "torch.Size([1, 851]) torch.Size([1, 851])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 246]) torch.Size([1, 246])\n",
            "torch.Size([1, 215]) torch.Size([1, 215])\n",
            "torch.Size([1, 132]) torch.Size([1, 132])\n",
            "torch.Size([1, 103]) torch.Size([1, 103])\n",
            "torch.Size([1, 120]) torch.Size([1, 120])\n",
            "torch.Size([1, 581]) torch.Size([1, 581])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 121]) torch.Size([1, 121])\n",
            "torch.Size([1, 282]) torch.Size([1, 282])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 775]) torch.Size([1, 775])\n",
            "torch.Size([1, 184]) torch.Size([1, 184])\n",
            "torch.Size([1, 992]) torch.Size([1, 992])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 282]) torch.Size([1, 282])\n",
            "torch.Size([1, 505]) torch.Size([1, 505])\n",
            "torch.Size([1, 947]) torch.Size([1, 947])\n",
            "torch.Size([1, 175]) torch.Size([1, 175])\n",
            "torch.Size([1, 429]) torch.Size([1, 429])\n",
            "torch.Size([1, 1018]) torch.Size([1, 1018])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 126]) torch.Size([1, 126])\n",
            "torch.Size([1, 137]) torch.Size([1, 137])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 175]) torch.Size([1, 175])\n",
            "torch.Size([1, 402]) torch.Size([1, 402])\n",
            "torch.Size([1, 918]) torch.Size([1, 918])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 229]) torch.Size([1, 229])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 248]) torch.Size([1, 248])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 215]) torch.Size([1, 215])\n",
            "torch.Size([1, 128]) torch.Size([1, 128])\n",
            "torch.Size([1, 757]) torch.Size([1, 757])\n",
            "torch.Size([1, 187]) torch.Size([1, 187])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 608]) torch.Size([1, 608])\n",
            "torch.Size([1, 898]) torch.Size([1, 898])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 513]) torch.Size([1, 513])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 250]) torch.Size([1, 250])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 98]) torch.Size([1, 98])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 948]) torch.Size([1, 948])\n",
            "torch.Size([1, 320]) torch.Size([1, 320])\n",
            "torch.Size([1, 935]) torch.Size([1, 935])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 213]) torch.Size([1, 213])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 216]) torch.Size([1, 216])\n",
            "torch.Size([1, 115]) torch.Size([1, 115])\n",
            "torch.Size([1, 182]) torch.Size([1, 182])\n",
            "torch.Size([1, 393]) torch.Size([1, 393])\n",
            "torch.Size([1, 984]) torch.Size([1, 984])\n",
            "torch.Size([1, 526]) torch.Size([1, 526])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 112]) torch.Size([1, 112])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 112]) torch.Size([1, 112])\n",
            "torch.Size([1, 111]) torch.Size([1, 111])\n",
            "torch.Size([1, 570]) torch.Size([1, 570])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 676]) torch.Size([1, 676])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 122]) torch.Size([1, 122])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 315]) torch.Size([1, 315])\n",
            "torch.Size([1, 77]) torch.Size([1, 77])\n",
            "torch.Size([1, 77]) torch.Size([1, 77])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 912]) torch.Size([1, 912])\n",
            "torch.Size([1, 192]) torch.Size([1, 192])\n",
            "torch.Size([1, 343]) torch.Size([1, 343])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 380]) torch.Size([1, 380])\n",
            "torch.Size([1, 351]) torch.Size([1, 351])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 305]) torch.Size([1, 305])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 143]) torch.Size([1, 143])\n",
            "torch.Size([1, 410]) torch.Size([1, 410])\n",
            "torch.Size([1, 251]) torch.Size([1, 251])\n",
            "torch.Size([1, 866]) torch.Size([1, 866])\n",
            "torch.Size([1, 125]) torch.Size([1, 125])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 132]) torch.Size([1, 132])\n",
            "torch.Size([1, 869]) torch.Size([1, 869])\n",
            "torch.Size([1, 206]) torch.Size([1, 206])\n",
            "torch.Size([1, 292]) torch.Size([1, 292])\n",
            "torch.Size([1, 113]) torch.Size([1, 113])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 121]) torch.Size([1, 121])\n",
            "torch.Size([1, 319]) torch.Size([1, 319])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 78]) torch.Size([1, 78])\n",
            "torch.Size([1, 503]) torch.Size([1, 503])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 617]) torch.Size([1, 617])\n",
            "torch.Size([1, 294]) torch.Size([1, 294])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 82]) torch.Size([1, 82])\n",
            "torch.Size([1, 209]) torch.Size([1, 209])\n",
            "torch.Size([1, 600]) torch.Size([1, 600])\n",
            "torch.Size([1, 247]) torch.Size([1, 247])\n",
            "torch.Size([1, 98]) torch.Size([1, 98])\n",
            "torch.Size([1, 797]) torch.Size([1, 797])\n",
            "torch.Size([1, 118]) torch.Size([1, 118])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 249]) torch.Size([1, 249])\n",
            "torch.Size([1, 338]) torch.Size([1, 338])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 647]) torch.Size([1, 647])\n",
            "torch.Size([1, 196]) torch.Size([1, 196])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 204]) torch.Size([1, 204])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 115]) torch.Size([1, 115])\n",
            "torch.Size([1, 108]) torch.Size([1, 108])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 341]) torch.Size([1, 341])\n",
            "torch.Size([1, 382]) torch.Size([1, 382])\n",
            "torch.Size([1, 112]) torch.Size([1, 112])\n",
            "torch.Size([1, 350]) torch.Size([1, 350])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 273]) torch.Size([1, 273])\n",
            "torch.Size([1, 84]) torch.Size([1, 84])\n",
            "torch.Size([1, 207]) torch.Size([1, 207])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 202]) torch.Size([1, 202])\n",
            "torch.Size([1, 930]) torch.Size([1, 930])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 221]) torch.Size([1, 221])\n",
            "torch.Size([1, 429]) torch.Size([1, 429])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 509]) torch.Size([1, 509])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 265]) torch.Size([1, 265])\n",
            "torch.Size([1, 439]) torch.Size([1, 439])\n",
            "torch.Size([1, 926]) torch.Size([1, 926])\n",
            "torch.Size([1, 134]) torch.Size([1, 134])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 478]) torch.Size([1, 478])\n",
            "torch.Size([1, 289]) torch.Size([1, 289])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 193]) torch.Size([1, 193])\n",
            "torch.Size([1, 316]) torch.Size([1, 316])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 288]) torch.Size([1, 288])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 121]) torch.Size([1, 121])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 459]) torch.Size([1, 459])\n",
            "torch.Size([1, 1021]) torch.Size([1, 1021])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 283]) torch.Size([1, 283])\n",
            "torch.Size([1, 233]) torch.Size([1, 233])\n",
            "torch.Size([1, 97]) torch.Size([1, 97])\n",
            "torch.Size([1, 237]) torch.Size([1, 237])\n",
            "torch.Size([1, 242]) torch.Size([1, 242])\n",
            "torch.Size([1, 119]) torch.Size([1, 119])\n",
            "torch.Size([1, 414]) torch.Size([1, 414])\n",
            "torch.Size([1, 150]) torch.Size([1, 150])\n",
            "torch.Size([1, 210]) torch.Size([1, 210])\n",
            "torch.Size([1, 124]) torch.Size([1, 124])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 141]) torch.Size([1, 141])\n",
            "torch.Size([1, 414]) torch.Size([1, 414])\n",
            "torch.Size([1, 84]) torch.Size([1, 84])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 126]) torch.Size([1, 126])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 662]) torch.Size([1, 662])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 982]) torch.Size([1, 982])\n",
            "torch.Size([1, 557]) torch.Size([1, 557])\n",
            "torch.Size([1, 114]) torch.Size([1, 114])\n",
            "torch.Size([1, 223]) torch.Size([1, 223])\n",
            "torch.Size([1, 120]) torch.Size([1, 120])\n",
            "torch.Size([1, 129]) torch.Size([1, 129])\n",
            "torch.Size([1, 399]) torch.Size([1, 399])\n",
            "torch.Size([1, 181]) torch.Size([1, 181])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 238]) torch.Size([1, 238])\n",
            "torch.Size([1, 281]) torch.Size([1, 281])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 151]) torch.Size([1, 151])\n",
            "torch.Size([1, 732]) torch.Size([1, 732])\n",
            "torch.Size([1, 282]) torch.Size([1, 282])\n",
            "torch.Size([1, 145]) torch.Size([1, 145])\n",
            "torch.Size([1, 252]) torch.Size([1, 252])\n",
            "torch.Size([1, 422]) torch.Size([1, 422])\n",
            "torch.Size([1, 776]) torch.Size([1, 776])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 202]) torch.Size([1, 202])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 245]) torch.Size([1, 245])\n",
            "torch.Size([1, 198]) torch.Size([1, 198])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 591]) torch.Size([1, 591])\n",
            "torch.Size([1, 114]) torch.Size([1, 114])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 181]) torch.Size([1, 181])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 713]) torch.Size([1, 713])\n",
            "torch.Size([1, 114]) torch.Size([1, 114])\n",
            "torch.Size([1, 1002]) torch.Size([1, 1002])\n",
            "torch.Size([1, 261]) torch.Size([1, 261])\n",
            "torch.Size([1, 91]) torch.Size([1, 91])\n",
            "torch.Size([1, 204]) torch.Size([1, 204])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 982]) torch.Size([1, 982])\n",
            "torch.Size([1, 473]) torch.Size([1, 473])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 111]) torch.Size([1, 111])\n",
            "torch.Size([1, 166]) torch.Size([1, 166])\n",
            "torch.Size([1, 303]) torch.Size([1, 303])\n",
            "torch.Size([1, 391]) torch.Size([1, 391])\n",
            "torch.Size([1, 98]) torch.Size([1, 98])\n",
            "torch.Size([1, 204]) torch.Size([1, 204])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 78]) torch.Size([1, 78])\n",
            "torch.Size([1, 113]) torch.Size([1, 113])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 111]) torch.Size([1, 111])\n",
            "torch.Size([1, 920]) torch.Size([1, 920])\n",
            "torch.Size([1, 188]) torch.Size([1, 188])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 798]) torch.Size([1, 798])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 711]) torch.Size([1, 711])\n",
            "torch.Size([1, 807]) torch.Size([1, 807])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 371]) torch.Size([1, 371])\n",
            "torch.Size([1, 796]) torch.Size([1, 796])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 263]) torch.Size([1, 263])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 78]) torch.Size([1, 78])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 417]) torch.Size([1, 417])\n",
            "torch.Size([1, 115]) torch.Size([1, 115])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 207]) torch.Size([1, 207])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 149]) torch.Size([1, 149])\n",
            "torch.Size([1, 80]) torch.Size([1, 80])\n",
            "torch.Size([1, 835]) torch.Size([1, 835])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 251]) torch.Size([1, 251])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 295]) torch.Size([1, 295])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 933]) torch.Size([1, 933])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 433]) torch.Size([1, 433])\n",
            "torch.Size([1, 840]) torch.Size([1, 840])\n",
            "torch.Size([1, 146]) torch.Size([1, 146])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 349]) torch.Size([1, 349])\n",
            "torch.Size([1, 827]) torch.Size([1, 827])\n",
            "torch.Size([1, 135]) torch.Size([1, 135])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 345]) torch.Size([1, 345])\n",
            "torch.Size([1, 782]) torch.Size([1, 782])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 104]) torch.Size([1, 104])\n",
            "torch.Size([1, 86]) torch.Size([1, 86])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 116]) torch.Size([1, 116])\n",
            "torch.Size([1, 286]) torch.Size([1, 286])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 566]) torch.Size([1, 566])\n",
            "torch.Size([1, 84]) torch.Size([1, 84])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 211]) torch.Size([1, 211])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 192]) torch.Size([1, 192])\n",
            "torch.Size([1, 120]) torch.Size([1, 120])\n",
            "torch.Size([1, 217]) torch.Size([1, 217])\n",
            "torch.Size([1, 649]) torch.Size([1, 649])\n",
            "torch.Size([1, 273]) torch.Size([1, 273])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 177]) torch.Size([1, 177])\n",
            "torch.Size([1, 136]) torch.Size([1, 136])\n",
            "torch.Size([1, 247]) torch.Size([1, 247])\n",
            "torch.Size([1, 85]) torch.Size([1, 85])\n",
            "torch.Size([1, 120]) torch.Size([1, 120])\n",
            "torch.Size([1, 214]) torch.Size([1, 214])\n",
            "torch.Size([1, 107]) torch.Size([1, 107])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 198]) torch.Size([1, 198])\n",
            "torch.Size([1, 222]) torch.Size([1, 222])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 344]) torch.Size([1, 344])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 289]) torch.Size([1, 289])\n",
            "torch.Size([1, 117]) torch.Size([1, 117])\n",
            "torch.Size([1, 99]) torch.Size([1, 99])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 401]) torch.Size([1, 401])\n",
            "torch.Size([1, 825]) torch.Size([1, 825])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 78]) torch.Size([1, 78])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 263]) torch.Size([1, 263])\n",
            "torch.Size([1, 240]) torch.Size([1, 240])\n",
            "torch.Size([1, 212]) torch.Size([1, 212])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 249]) torch.Size([1, 249])\n",
            "torch.Size([1, 532]) torch.Size([1, 532])\n",
            "torch.Size([1, 918]) torch.Size([1, 918])\n",
            "torch.Size([1, 339]) torch.Size([1, 339])\n",
            "torch.Size([1, 108]) torch.Size([1, 108])\n",
            "torch.Size([1, 201]) torch.Size([1, 201])\n",
            "torch.Size([1, 253]) torch.Size([1, 253])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 626]) torch.Size([1, 626])\n",
            "torch.Size([1, 177]) torch.Size([1, 177])\n",
            "torch.Size([1, 83]) torch.Size([1, 83])\n",
            "torch.Size([1, 203]) torch.Size([1, 203])\n",
            "torch.Size([1, 318]) torch.Size([1, 318])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 185]) torch.Size([1, 185])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 367]) torch.Size([1, 367])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 148]) torch.Size([1, 148])\n",
            "torch.Size([1, 438]) torch.Size([1, 438])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 98]) torch.Size([1, 98])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 177]) torch.Size([1, 177])\n",
            "torch.Size([1, 211]) torch.Size([1, 211])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 88]) torch.Size([1, 88])\n",
            "torch.Size([1, 946]) torch.Size([1, 946])\n",
            "torch.Size([1, 380]) torch.Size([1, 380])\n",
            "torch.Size([1, 690]) torch.Size([1, 690])\n",
            "torch.Size([1, 847]) torch.Size([1, 847])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 225]) torch.Size([1, 225])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 252]) torch.Size([1, 252])\n",
            "torch.Size([1, 243]) torch.Size([1, 243])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 112]) torch.Size([1, 112])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 168]) torch.Size([1, 168])\n",
            "torch.Size([1, 213]) torch.Size([1, 213])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 751]) torch.Size([1, 751])\n",
            "torch.Size([1, 78]) torch.Size([1, 78])\n",
            "torch.Size([1, 105]) torch.Size([1, 105])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 207]) torch.Size([1, 207])\n",
            "torch.Size([1, 345]) torch.Size([1, 345])\n",
            "torch.Size([1, 538]) torch.Size([1, 538])\n",
            "torch.Size([1, 191]) torch.Size([1, 191])\n",
            "torch.Size([1, 223]) torch.Size([1, 223])\n",
            "torch.Size([1, 567]) torch.Size([1, 567])\n",
            "torch.Size([1, 102]) torch.Size([1, 102])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 131]) torch.Size([1, 131])\n",
            "torch.Size([1, 84]) torch.Size([1, 84])\n",
            "torch.Size([1, 81]) torch.Size([1, 81])\n",
            "torch.Size([1, 277]) torch.Size([1, 277])\n",
            "torch.Size([1, 108]) torch.Size([1, 108])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 401]) torch.Size([1, 401])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 256]) torch.Size([1, 256])\n",
            "torch.Size([1, 248]) torch.Size([1, 248])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 100]) torch.Size([1, 100])\n",
            "torch.Size([1, 240]) torch.Size([1, 240])\n",
            "torch.Size([1, 109]) torch.Size([1, 109])\n",
            "torch.Size([1, 191]) torch.Size([1, 191])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 927]) torch.Size([1, 927])\n",
            "torch.Size([1, 418]) torch.Size([1, 418])\n",
            "torch.Size([1, 79]) torch.Size([1, 79])\n",
            "torch.Size([1, 338]) torch.Size([1, 338])\n",
            "torch.Size([1, 135]) torch.Size([1, 135])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 89]) torch.Size([1, 89])\n",
            "torch.Size([1, 92]) torch.Size([1, 92])\n",
            "torch.Size([1, 197]) torch.Size([1, 197])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 114]) torch.Size([1, 114])\n",
            "torch.Size([1, 545]) torch.Size([1, 545])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 106]) torch.Size([1, 106])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n",
            "torch.Size([1, 93]) torch.Size([1, 93])\n",
            "torch.Size([1, 132]) torch.Size([1, 132])\n",
            "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
            "torch.Size([1, 318]) torch.Size([1, 318])\n",
            "torch.Size([1, 96]) torch.Size([1, 96])\n",
            "torch.Size([1, 198]) torch.Size([1, 198])\n",
            "torch.Size([1, 193]) torch.Size([1, 193])\n",
            "torch.Size([1, 90]) torch.Size([1, 90])\n",
            "torch.Size([1, 115]) torch.Size([1, 115])\n",
            "torch.Size([1, 194]) torch.Size([1, 194])\n",
            "torch.Size([1, 223]) torch.Size([1, 223])\n",
            "torch.Size([1, 798]) torch.Size([1, 798])\n",
            "torch.Size([1, 101]) torch.Size([1, 101])\n",
            "torch.Size([1, 124]) torch.Size([1, 124])\n",
            "torch.Size([1, 94]) torch.Size([1, 94])\n",
            "torch.Size([1, 235]) torch.Size([1, 235])\n",
            "torch.Size([1, 193]) torch.Size([1, 193])\n",
            "torch.Size([1, 121]) torch.Size([1, 121])\n",
            "torch.Size([1, 193]) torch.Size([1, 193])\n",
            "torch.Size([1, 306]) torch.Size([1, 306])\n",
            "torch.Size([1, 118]) torch.Size([1, 118])\n",
            "torch.Size([1, 542]) torch.Size([1, 542])\n",
            "torch.Size([1, 87]) torch.Size([1, 87])\n",
            "torch.Size([1, 95]) torch.Size([1, 95])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download function"
      ],
      "metadata": {
        "id": "Me6htB5G5svp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
        "# Source for \"Build a Large Language Model From Scratch\"\n",
        "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
        "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        response = requests.get(download_url, stream=True, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "        # Check if file exists and has same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size and file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return True\n",
        "\n",
        "        block_size = 1024  # 1 KB\n",
        "        desc = os.path.basename(download_url)\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
        "            with open(destination, \"wb\") as file:\n",
        "                for chunk in response.iter_content(chunk_size=block_size):\n",
        "                    if chunk:\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except requests.exceptions.RequestException:\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except requests.exceptions.RequestException:\n",
        "                pass\n",
        "\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "LzmwEuFX6Ok4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "5p86FH646vNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
        "# Source for \"Build a Large Language Model From Scratch\"\n",
        "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
        "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
        "#\n",
        "# This file collects all the relevant code that we covered thus far\n",
        "# throughout Chapters 2-6.\n",
        "# This file can be run as a standalone script.\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 2\n",
        "#####################################\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 3\n",
        "#####################################\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 4\n",
        "#####################################\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 5\n",
        "#####################################\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
        "            # subtract rowwise max before softmax\n",
        "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xZgLnqMV6mZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading Pre-trained Model"
      ],
      "metadata": {
        "id": "if5KY05_6zeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfPBwWVe5wYq",
        "outputId": "960be64d-8c0e-476f-f3be-b429e0591a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initial Losses"
      ],
      "metadata": {
        "id": "WTYHD6dvAiE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwGyi9zA_Dus",
        "outputId": "1cabdbc5-baec-42cc-b22f-04f48b66f0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.7994977951049806\n",
            "Validation loss: 3.1300379276275634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.pos_emb.num_embeddings = 256"
      ],
      "metadata": {
        "id": "4_jZhq62fz4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###New Training"
      ],
      "metadata": {
        "id": "bAwVmkYMAdX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "6RD9T-ijejdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u-1KrzQAc0l",
        "outputId": "8faf95dd-3248-455e-e160-1e16b14a40c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 1.496, Val loss 1.598\n",
            "Ep 1 (Step 000005): Train loss 1.293, Val loss 1.628\n",
            "Ep 1 (Step 000010): Train loss 1.731, Val loss 1.651\n",
            "Ep 1 (Step 000015): Train loss 1.813, Val loss 1.657\n",
            "Ep 1 (Step 000020): Train loss 1.376, Val loss 1.659\n",
            "Ep 1 (Step 000025): Train loss 1.525, Val loss 1.655\n",
            "Ep 1 (Step 000030): Train loss 2.088, Val loss 1.649\n",
            "Ep 1 (Step 000035): Train loss 2.148, Val loss 1.642\n",
            "Ep 1 (Step 000040): Train loss 2.169, Val loss 1.646\n",
            "Ep 1 (Step 000045): Train loss 2.224, Val loss 1.646\n",
            "Ep 1 (Step 000050): Train loss 0.983, Val loss 1.578\n",
            "Ep 1 (Step 000055): Train loss 1.582, Val loss 1.571\n",
            "Ep 1 (Step 000060): Train loss 1.419, Val loss 1.565\n",
            "Ep 1 (Step 000065): Train loss 1.299, Val loss 1.551\n",
            "Ep 1 (Step 000070): Train loss 1.625, Val loss 1.530\n",
            "Ep 1 (Step 000075): Train loss 1.514, Val loss 1.516\n",
            "Ep 1 (Step 000080): Train loss 1.703, Val loss 1.513\n",
            "Ep 1 (Step 000085): Train loss 1.950, Val loss 1.518\n",
            "Ep 1 (Step 000090): Train loss 1.436, Val loss 1.534\n",
            "Ep 1 (Step 000095): Train loss 1.350, Val loss 1.533\n",
            "Ep 1 (Step 000100): Train loss 0.692, Val loss 1.529\n",
            "Ep 1 (Step 000105): Train loss 1.434, Val loss 1.528\n",
            "Ep 1 (Step 000110): Train loss 1.885, Val loss 1.513\n",
            "Ep 1 (Step 000115): Train loss 1.109, Val loss 1.491\n",
            "Ep 1 (Step 000120): Train loss 1.919, Val loss 1.466\n",
            "Ep 1 (Step 000125): Train loss 1.147, Val loss 1.464\n",
            "Ep 1 (Step 000130): Train loss 0.782, Val loss 1.478\n",
            "Ep 1 (Step 000135): Train loss 0.978, Val loss 1.470\n",
            "Ep 1 (Step 000140): Train loss 1.613, Val loss 1.468\n",
            "Ep 1 (Step 000145): Train loss 1.018, Val loss 1.476\n",
            "Ep 1 (Step 000150): Train loss 0.831, Val loss 1.470\n",
            "Ep 1 (Step 000155): Train loss 1.575, Val loss 1.474\n",
            "Ep 1 (Step 000160): Train loss 1.839, Val loss 1.478\n",
            "Ep 1 (Step 000165): Train loss 1.030, Val loss 1.478\n",
            "Ep 1 (Step 000170): Train loss 1.652, Val loss 1.475\n",
            "Ep 1 (Step 000175): Train loss 1.474, Val loss 1.466\n",
            "Ep 1 (Step 000180): Train loss 1.700, Val loss 1.462\n",
            "Ep 1 (Step 000185): Train loss 1.333, Val loss 1.463\n",
            "Ep 1 (Step 000190): Train loss 1.937, Val loss 1.456\n",
            "Ep 1 (Step 000195): Train loss 0.942, Val loss 1.447\n",
            "Ep 1 (Step 000200): Train loss 1.350, Val loss 1.435\n",
            "Ep 1 (Step 000205): Train loss 2.003, Val loss 1.431\n",
            "Ep 1 (Step 000210): Train loss 1.303, Val loss 1.450\n",
            "Ep 1 (Step 000215): Train loss 1.329, Val loss 1.472\n",
            "Ep 1 (Step 000220): Train loss 1.121, Val loss 1.451\n",
            "Ep 1 (Step 000225): Train loss 0.650, Val loss 1.455\n",
            "Ep 1 (Step 000230): Train loss 1.480, Val loss 1.470\n",
            "Ep 1 (Step 000235): Train loss 0.871, Val loss 1.476\n",
            "Ep 1 (Step 000240): Train loss 0.827, Val loss 1.468\n",
            "Ep 1 (Step 000245): Train loss 1.265, Val loss 1.454\n",
            "Ep 1 (Step 000250): Train loss 0.988, Val loss 1.426\n",
            "Ep 1 (Step 000255): Train loss 1.332, Val loss 1.411\n",
            "Ep 1 (Step 000260): Train loss 1.425, Val loss 1.413\n",
            "Ep 1 (Step 000265): Train loss 0.899, Val loss 1.420\n",
            "Ep 1 (Step 000270): Train loss 1.211, Val loss 1.432\n",
            "Ep 1 (Step 000275): Train loss 1.218, Val loss 1.439\n",
            "Ep 1 (Step 000280): Train loss 1.090, Val loss 1.414\n",
            "Ep 1 (Step 000285): Train loss 1.402, Val loss 1.418\n",
            "Ep 1 (Step 000290): Train loss 1.142, Val loss 1.411\n",
            "Ep 1 (Step 000295): Train loss 1.108, Val loss 1.416\n",
            "Ep 1 (Step 000300): Train loss 1.051, Val loss 1.421\n",
            "Ep 1 (Step 000305): Train loss 1.628, Val loss 1.424\n",
            "Ep 1 (Step 000310): Train loss 1.544, Val loss 1.425\n",
            "Ep 1 (Step 000315): Train loss 1.260, Val loss 1.424\n",
            "Ep 1 (Step 000320): Train loss 1.482, Val loss 1.415\n",
            "Ep 1 (Step 000325): Train loss 1.389, Val loss 1.407\n",
            "Ep 1 (Step 000330): Train loss 1.243, Val loss 1.407\n",
            "Ep 1 (Step 000335): Train loss 1.332, Val loss 1.412\n",
            "Ep 1 (Step 000340): Train loss 1.539, Val loss 1.421\n",
            "Ep 1 (Step 000345): Train loss 0.910, Val loss 1.413\n",
            "Ep 1 (Step 000350): Train loss 1.367, Val loss 1.403\n",
            "Ep 1 (Step 000355): Train loss 1.070, Val loss 1.403\n",
            "Ep 1 (Step 000360): Train loss 1.112, Val loss 1.409\n",
            "Ep 1 (Step 000365): Train loss 0.672, Val loss 1.409\n",
            "Ep 1 (Step 000370): Train loss 1.354, Val loss 1.411\n",
            "Ep 1 (Step 000375): Train loss 1.214, Val loss 1.437\n",
            "Ep 1 (Step 000380): Train loss 1.093, Val loss 1.458\n",
            "Ep 1 (Step 000385): Train loss 1.212, Val loss 1.469\n",
            "Ep 1 (Step 000390): Train loss 1.321, Val loss 1.475\n",
            "Ep 1 (Step 000395): Train loss 1.319, Val loss 1.445\n",
            "Ep 1 (Step 000400): Train loss 0.944, Val loss 1.441\n",
            "Ep 1 (Step 000405): Train loss 1.020, Val loss 1.441\n",
            "Ep 1 (Step 000410): Train loss 1.144, Val loss 1.428\n",
            "Ep 1 (Step 000415): Train loss 1.090, Val loss 1.431\n",
            "Ep 1 (Step 000420): Train loss 0.717, Val loss 1.437\n",
            "Ep 1 (Step 000425): Train loss 1.375, Val loss 1.434\n",
            "Ep 1 (Step 000430): Train loss 2.018, Val loss 1.427\n",
            "Ep 1 (Step 000435): Train loss 1.142, Val loss 1.422\n",
            "Ep 1 (Step 000440): Train loss 0.847, Val loss 1.420\n",
            "Ep 1 (Step 000445): Train loss 1.728, Val loss 1.418\n",
            "Ep 1 (Step 000450): Train loss 0.622, Val loss 1.426\n",
            "Ep 1 (Step 000455): Train loss 1.099, Val loss 1.433\n",
            "Ep 1 (Step 000460): Train loss 1.192, Val loss 1.458\n",
            "Ep 1 (Step 000465): Train loss 0.874, Val loss 1.487\n",
            "Ep 1 (Step 000470): Train loss 0.638, Val loss 1.494\n",
            "Ep 1 (Step 000475): Train loss 0.874, Val loss 1.489\n",
            "Ep 1 (Step 000480): Train loss 0.714, Val loss 1.491\n",
            "Ep 1 (Step 000485): Train loss 1.076, Val loss 1.486\n",
            "Ep 1 (Step 000490): Train loss 0.921, Val loss 1.466\n",
            "Ep 1 (Step 000495): Train loss 0.956, Val loss 1.455\n",
            "Ep 1 (Step 000500): Train loss 0.856, Val loss 1.445\n",
            "Ep 1 (Step 000505): Train loss 0.830, Val loss 1.459\n",
            "Ep 1 (Step 000510): Train loss 0.930, Val loss 1.471\n",
            "Ep 1 (Step 000515): Train loss 1.021, Val loss 1.303\n",
            "Ep 1 (Step 000520): Train loss 0.592, Val loss 1.272\n",
            "Ep 1 (Step 000525): Train loss 0.820, Val loss 1.270\n",
            "Ep 1 (Step 000530): Train loss 1.396, Val loss 1.265\n",
            "Ep 1 (Step 000535): Train loss 1.013, Val loss 1.256\n",
            "Ep 1 (Step 000540): Train loss 0.822, Val loss 1.242\n",
            "Ep 1 (Step 000545): Train loss 0.809, Val loss 1.235\n",
            "Ep 1 (Step 000550): Train loss 0.760, Val loss 1.232\n",
            "Ep 1 (Step 000555): Train loss 0.446, Val loss 1.232\n",
            "Ep 1 (Step 000560): Train loss 1.444, Val loss 1.232\n",
            "Ep 1 (Step 000565): Train loss 0.856, Val loss 1.238\n",
            "Ep 1 (Step 000570): Train loss 0.903, Val loss 1.235\n",
            "Ep 1 (Step 000575): Train loss 1.573, Val loss 1.240\n",
            "Ep 1 (Step 000580): Train loss 0.637, Val loss 1.254\n",
            "Ep 1 (Step 000585): Train loss 1.033, Val loss 1.267\n",
            "Ep 1 (Step 000590): Train loss 0.695, Val loss 1.276\n",
            "Ep 1 (Step 000595): Train loss 0.942, Val loss 1.241\n",
            "Ep 1 (Step 000600): Train loss 1.622, Val loss 1.182\n",
            "Ep 1 (Step 000605): Train loss 1.068, Val loss 1.151\n",
            "Ep 1 (Step 000610): Train loss 0.969, Val loss 1.135\n",
            "Ep 1 (Step 000615): Train loss 0.859, Val loss 1.125\n",
            "Ep 1 (Step 000620): Train loss 0.862, Val loss 1.123\n",
            "Ep 1 (Step 000625): Train loss 0.762, Val loss 1.127\n",
            "Ep 1 (Step 000630): Train loss 1.008, Val loss 1.139\n",
            "Ep 1 (Step 000635): Train loss 0.766, Val loss 1.144\n",
            "Ep 1 (Step 000640): Train loss 0.882, Val loss 1.146\n",
            "Ep 1 (Step 000645): Train loss 1.117, Val loss 1.142\n",
            "Ep 1 (Step 000650): Train loss 0.888, Val loss 1.142\n",
            "Ep 1 (Step 000655): Train loss 0.587, Val loss 1.152\n",
            "Ep 1 (Step 000660): Train loss 1.096, Val loss 1.163\n",
            "Ep 1 (Step 000665): Train loss 0.846, Val loss 1.162\n",
            "Ep 1 (Step 000670): Train loss 1.145, Val loss 1.156\n",
            "Ep 1 (Step 000675): Train loss 0.443, Val loss 1.151\n",
            "Ep 1 (Step 000680): Train loss 0.841, Val loss 1.149\n",
            "Ep 1 (Step 000685): Train loss 0.536, Val loss 1.137\n",
            "Ep 1 (Step 000690): Train loss 0.933, Val loss 1.125\n",
            "Ep 1 (Step 000695): Train loss 0.650, Val loss 1.127\n",
            "Ep 1 (Step 000700): Train loss 0.466, Val loss 1.127\n",
            "Ep 1 (Step 000705): Train loss 0.483, Val loss 1.224\n",
            "Ep 1 (Step 000710): Train loss 0.959, Val loss 1.320\n",
            "Ep 1 (Step 000715): Train loss 1.471, Val loss 1.205\n",
            "Ep 1 (Step 000720): Train loss 0.874, Val loss 1.163\n",
            "Ep 1 (Step 000725): Train loss 0.624, Val loss 1.188\n",
            "Ep 1 (Step 000730): Train loss 1.005, Val loss 1.168\n",
            "Ep 1 (Step 000735): Train loss 1.092, Val loss 1.161\n",
            "Ep 1 (Step 000740): Train loss 0.695, Val loss 1.155\n",
            "Ep 1 (Step 000745): Train loss 0.943, Val loss 1.152\n",
            "Ep 1 (Step 000750): Train loss 0.605, Val loss 1.139\n",
            "Ep 1 (Step 000755): Train loss 1.193, Val loss 1.125\n",
            "Ep 1 (Step 000760): Train loss 0.396, Val loss 1.115\n",
            "Ep 1 (Step 000765): Train loss 0.437, Val loss 1.050\n",
            "Ep 1 (Step 000770): Train loss 0.377, Val loss 1.041\n",
            "Ep 1 (Step 000775): Train loss 0.768, Val loss 1.048\n",
            "Ep 1 (Step 000780): Train loss 0.374, Val loss 1.054\n",
            "Ep 1 (Step 000785): Train loss 0.685, Val loss 1.042\n",
            "Ep 1 (Step 000790): Train loss 1.011, Val loss 1.032\n",
            "Ep 1 (Step 000795): Train loss 0.600, Val loss 1.020\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Answer the question based on the context provided below. \"Please provide the specific number of ACC opponents that the Fighting Irish are scheduled to play against in a typical season.\"  ### Input: Notre Dame's conference affiliations for all of its sports except football and fencing changed in July 2013 as a result of major conference realignment, and its fencing affiliation will change in July 2014. The Irish left the Big East for the ACC during a prolonged period of instability in the Big East; while they maintain their football independence, they have committed to play five games per season against ACC opponents. In ice hockey, the Irish were forced to find a new conference home after the Big Ten Conference's decision to add the sport in 2013–14 led to a cascade of conference moves that culminated in the dissolution of the school's former hockey home, the Central Collegiate Hockey Association, after the 2012–13 season. Notre Dame moved its hockey team to Hockey East. After Notre Dame joined the ACC, the conference announced it would add fencing as a sponsored sport beginning in the 2014–15 school year. There are many theories behind the adoption of the athletics moniker but it is known that the Fighting Irish name was used in the early 1920s with respect to the football team and was popularized by alumnus Francis Wallace in his New York Daily News columns. The official colors of Notre Dame are Navy Blue and Gold Rush which are worn in competition by its athletic teams. In addition, the color green is often worn because of the Fighting Irish nickname. The Notre Dame Leprechaun is the mascot of the athletic teams. Created by Theodore W. Drake in 1964, the leprechaun was first used on the football pocket schedule and later on the football program covers. The leprechaun was featured on the cover of Time in November 1964 and gained national exposure.  ### Response: five games per season  ### Response: five games per season<|endoftext|>The first time I saw the movie, I was in my early 20s, and I was completely lost. I had no idea what to expect. I was so confused that I\n",
            "Ep 2 (Step 000800): Train loss 0.763, Val loss 1.016\n",
            "Ep 2 (Step 000805): Train loss 0.592, Val loss 1.016\n",
            "Ep 2 (Step 000810): Train loss 0.678, Val loss 1.019\n",
            "Ep 2 (Step 000815): Train loss 1.023, Val loss 1.032\n",
            "Ep 2 (Step 000820): Train loss 0.721, Val loss 1.030\n",
            "Ep 2 (Step 000825): Train loss 0.311, Val loss 1.039\n",
            "Ep 2 (Step 000830): Train loss 0.378, Val loss 1.042\n",
            "Ep 2 (Step 000835): Train loss 0.732, Val loss 1.048\n",
            "Ep 2 (Step 000840): Train loss 0.610, Val loss 1.055\n",
            "Ep 2 (Step 000845): Train loss 0.968, Val loss 1.060\n",
            "Ep 2 (Step 000850): Train loss 0.695, Val loss 1.059\n",
            "Ep 2 (Step 000855): Train loss 0.618, Val loss 1.053\n",
            "Ep 2 (Step 000860): Train loss 0.621, Val loss 1.047\n",
            "Ep 2 (Step 000865): Train loss 0.560, Val loss 1.044\n",
            "Ep 2 (Step 000870): Train loss 0.316, Val loss 1.039\n",
            "Ep 2 (Step 000875): Train loss 0.943, Val loss 1.043\n",
            "Ep 2 (Step 000880): Train loss 1.296, Val loss 1.044\n",
            "Ep 2 (Step 000885): Train loss 1.129, Val loss 1.047\n",
            "Ep 2 (Step 000890): Train loss 0.329, Val loss 1.055\n",
            "Ep 2 (Step 000895): Train loss 0.607, Val loss 1.065\n",
            "Ep 2 (Step 000900): Train loss 0.876, Val loss 1.078\n",
            "Ep 2 (Step 000905): Train loss 0.582, Val loss 1.085\n",
            "Ep 2 (Step 000910): Train loss 0.463, Val loss 1.090\n",
            "Ep 2 (Step 000915): Train loss 1.307, Val loss 1.086\n",
            "Ep 2 (Step 000920): Train loss 0.606, Val loss 1.080\n",
            "Ep 2 (Step 000925): Train loss 0.314, Val loss 1.077\n",
            "Ep 2 (Step 000930): Train loss 0.673, Val loss 1.066\n",
            "Ep 2 (Step 000935): Train loss 0.502, Val loss 1.061\n",
            "Ep 2 (Step 000940): Train loss 0.733, Val loss 1.058\n",
            "Ep 2 (Step 000945): Train loss 0.315, Val loss 1.065\n",
            "Ep 2 (Step 000950): Train loss 0.818, Val loss 1.071\n",
            "Ep 2 (Step 000955): Train loss 1.041, Val loss 1.067\n",
            "Ep 2 (Step 000960): Train loss 0.751, Val loss 1.069\n",
            "Ep 2 (Step 000965): Train loss 0.754, Val loss 1.069\n",
            "Ep 2 (Step 000970): Train loss 0.705, Val loss 1.068\n",
            "Ep 2 (Step 000975): Train loss 0.795, Val loss 1.069\n",
            "Ep 2 (Step 000980): Train loss 0.816, Val loss 1.079\n",
            "Ep 2 (Step 000985): Train loss 0.565, Val loss 1.087\n",
            "Ep 2 (Step 000990): Train loss 0.642, Val loss 1.082\n",
            "Ep 2 (Step 000995): Train loss 0.753, Val loss 1.074\n",
            "Ep 2 (Step 001000): Train loss 0.619, Val loss 1.065\n",
            "Ep 2 (Step 001005): Train loss 1.059, Val loss 1.059\n",
            "Ep 2 (Step 001010): Train loss 0.655, Val loss 1.057\n",
            "Ep 2 (Step 001015): Train loss 0.458, Val loss 1.056\n",
            "Ep 2 (Step 001020): Train loss 0.638, Val loss 1.073\n",
            "Ep 2 (Step 001025): Train loss 0.649, Val loss 1.079\n",
            "Ep 2 (Step 001030): Train loss 0.840, Val loss 1.076\n",
            "Ep 2 (Step 001035): Train loss 0.640, Val loss 1.065\n",
            "Ep 2 (Step 001040): Train loss 0.602, Val loss 1.067\n",
            "Ep 2 (Step 001045): Train loss 0.599, Val loss 1.079\n",
            "Ep 2 (Step 001050): Train loss 0.694, Val loss 1.076\n",
            "Ep 2 (Step 001055): Train loss 0.311, Val loss 1.073\n",
            "Ep 2 (Step 001060): Train loss 0.520, Val loss 1.074\n",
            "Ep 2 (Step 001065): Train loss 0.562, Val loss 1.061\n",
            "Ep 2 (Step 001070): Train loss 0.208, Val loss 1.049\n",
            "Ep 2 (Step 001075): Train loss 0.188, Val loss 1.044\n",
            "Ep 2 (Step 001080): Train loss 0.636, Val loss 1.042\n",
            "Ep 2 (Step 001085): Train loss 0.334, Val loss 1.050\n",
            "Ep 2 (Step 001090): Train loss 0.529, Val loss 1.057\n",
            "Ep 2 (Step 001095): Train loss 1.197, Val loss 1.058\n",
            "Ep 2 (Step 001100): Train loss 1.289, Val loss 1.055\n",
            "Ep 2 (Step 001105): Train loss 0.997, Val loss 1.057\n",
            "Ep 2 (Step 001110): Train loss 0.866, Val loss 1.063\n",
            "Ep 2 (Step 001115): Train loss 0.994, Val loss 1.069\n",
            "Ep 2 (Step 001120): Train loss 0.480, Val loss 1.074\n",
            "Ep 2 (Step 001125): Train loss 0.560, Val loss 1.080\n",
            "Ep 2 (Step 001130): Train loss 0.300, Val loss 1.082\n",
            "Ep 2 (Step 001135): Train loss 0.516, Val loss 1.065\n",
            "Ep 2 (Step 001140): Train loss 0.488, Val loss 1.061\n",
            "Ep 2 (Step 001145): Train loss 0.258, Val loss 1.058\n",
            "Ep 2 (Step 001150): Train loss 0.593, Val loss 1.058\n",
            "Ep 2 (Step 001155): Train loss 0.581, Val loss 1.056\n",
            "Ep 2 (Step 001160): Train loss 0.875, Val loss 1.058\n",
            "Ep 2 (Step 001165): Train loss 0.619, Val loss 1.055\n",
            "Ep 2 (Step 001170): Train loss 0.290, Val loss 1.052\n",
            "Ep 2 (Step 001175): Train loss 0.376, Val loss 1.044\n",
            "Ep 2 (Step 001180): Train loss 0.812, Val loss 1.042\n",
            "Ep 2 (Step 001185): Train loss 0.882, Val loss 1.045\n",
            "Ep 2 (Step 001190): Train loss 0.295, Val loss 1.049\n",
            "Ep 2 (Step 001195): Train loss 0.341, Val loss 1.053\n",
            "Ep 2 (Step 001200): Train loss 0.421, Val loss 1.056\n",
            "Ep 2 (Step 001205): Train loss 0.441, Val loss 1.057\n",
            "Ep 2 (Step 001210): Train loss 1.112, Val loss 1.063\n",
            "Ep 2 (Step 001215): Train loss 0.595, Val loss 1.067\n",
            "Ep 2 (Step 001220): Train loss 0.501, Val loss 1.068\n",
            "Ep 2 (Step 001225): Train loss 0.537, Val loss 1.068\n",
            "Ep 2 (Step 001230): Train loss 0.429, Val loss 1.069\n",
            "Ep 2 (Step 001235): Train loss 0.198, Val loss 1.067\n",
            "Ep 2 (Step 001240): Train loss 0.217, Val loss 1.064\n",
            "Ep 2 (Step 001245): Train loss 0.214, Val loss 1.067\n",
            "Ep 2 (Step 001250): Train loss 0.618, Val loss 1.069\n",
            "Ep 2 (Step 001255): Train loss 0.711, Val loss 1.072\n",
            "Ep 2 (Step 001260): Train loss 0.498, Val loss 1.078\n",
            "Ep 2 (Step 001265): Train loss 0.207, Val loss 1.079\n",
            "Ep 2 (Step 001270): Train loss 0.219, Val loss 1.076\n",
            "Ep 2 (Step 001275): Train loss 0.458, Val loss 1.059\n",
            "Ep 2 (Step 001280): Train loss 0.568, Val loss 1.050\n",
            "Ep 2 (Step 001285): Train loss 0.668, Val loss 1.037\n",
            "Ep 2 (Step 001290): Train loss 0.685, Val loss 1.033\n",
            "Ep 2 (Step 001295): Train loss 1.385, Val loss 1.030\n",
            "Ep 2 (Step 001300): Train loss 0.643, Val loss 1.026\n",
            "Ep 2 (Step 001305): Train loss 1.141, Val loss 1.023\n",
            "Ep 2 (Step 001310): Train loss 0.446, Val loss 1.023\n",
            "Ep 2 (Step 001315): Train loss 0.456, Val loss 1.026\n",
            "Ep 2 (Step 001320): Train loss 1.121, Val loss 1.036\n",
            "Ep 2 (Step 001325): Train loss 0.257, Val loss 1.048\n",
            "Ep 2 (Step 001330): Train loss 0.961, Val loss 1.046\n",
            "Ep 2 (Step 001335): Train loss 1.031, Val loss 1.046\n",
            "Ep 2 (Step 001340): Train loss 0.642, Val loss 1.054\n",
            "Ep 2 (Step 001345): Train loss 0.526, Val loss 1.058\n",
            "Ep 2 (Step 001350): Train loss 0.343, Val loss 1.023\n",
            "Ep 2 (Step 001355): Train loss 0.173, Val loss 1.000\n",
            "Ep 2 (Step 001360): Train loss 1.142, Val loss 1.004\n",
            "Ep 2 (Step 001365): Train loss 1.175, Val loss 1.004\n",
            "Ep 2 (Step 001370): Train loss 0.500, Val loss 0.991\n",
            "Ep 2 (Step 001375): Train loss 0.571, Val loss 0.980\n",
            "Ep 2 (Step 001380): Train loss 0.498, Val loss 0.977\n",
            "Ep 2 (Step 001385): Train loss 0.481, Val loss 0.974\n",
            "Ep 2 (Step 001390): Train loss 1.164, Val loss 0.973\n",
            "Ep 2 (Step 001395): Train loss 0.595, Val loss 0.977\n",
            "Ep 2 (Step 001400): Train loss 0.824, Val loss 0.981\n",
            "Ep 2 (Step 001405): Train loss 0.673, Val loss 0.981\n",
            "Ep 2 (Step 001410): Train loss 0.841, Val loss 0.981\n",
            "Ep 2 (Step 001415): Train loss 0.448, Val loss 0.981\n",
            "Ep 2 (Step 001420): Train loss 0.632, Val loss 0.980\n",
            "Ep 2 (Step 001425): Train loss 0.763, Val loss 0.982\n",
            "Ep 2 (Step 001430): Train loss 0.303, Val loss 0.982\n",
            "Ep 2 (Step 001435): Train loss 0.491, Val loss 0.982\n",
            "Ep 2 (Step 001440): Train loss 0.869, Val loss 0.966\n",
            "Ep 2 (Step 001445): Train loss 0.311, Val loss 0.953\n",
            "Ep 2 (Step 001450): Train loss 0.138, Val loss 0.953\n",
            "Ep 2 (Step 001455): Train loss 0.824, Val loss 0.954\n",
            "Ep 2 (Step 001460): Train loss 0.988, Val loss 0.954\n",
            "Ep 2 (Step 001465): Train loss 1.258, Val loss 0.953\n",
            "Ep 2 (Step 001470): Train loss 0.830, Val loss 0.954\n",
            "Ep 2 (Step 001475): Train loss 0.168, Val loss 0.954\n",
            "Ep 2 (Step 001480): Train loss 0.602, Val loss 0.958\n",
            "Ep 2 (Step 001485): Train loss 0.237, Val loss 0.962\n",
            "Ep 2 (Step 001490): Train loss 0.504, Val loss 0.963\n",
            "Ep 2 (Step 001495): Train loss 0.784, Val loss 0.961\n",
            "Ep 2 (Step 001500): Train loss 0.677, Val loss 0.957\n",
            "Ep 2 (Step 001505): Train loss 0.162, Val loss 0.965\n",
            "Ep 2 (Step 001510): Train loss 0.343, Val loss 0.969\n",
            "Ep 2 (Step 001515): Train loss 1.001, Val loss 0.968\n",
            "Ep 2 (Step 001520): Train loss 0.778, Val loss 0.963\n",
            "Ep 2 (Step 001525): Train loss 0.504, Val loss 0.955\n",
            "Ep 2 (Step 001530): Train loss 0.195, Val loss 0.956\n",
            "Ep 2 (Step 001535): Train loss 0.247, Val loss 0.961\n",
            "Ep 2 (Step 001540): Train loss 0.205, Val loss 0.964\n",
            "Ep 2 (Step 001545): Train loss 0.623, Val loss 0.973\n",
            "Ep 2 (Step 001550): Train loss 0.353, Val loss 0.991\n",
            "Ep 2 (Step 001555): Train loss 0.932, Val loss 0.997\n",
            "Ep 2 (Step 001560): Train loss 0.623, Val loss 0.986\n",
            "Ep 2 (Step 001565): Train loss 0.720, Val loss 0.975\n",
            "Ep 2 (Step 001570): Train loss 0.494, Val loss 0.978\n",
            "Ep 2 (Step 001575): Train loss 0.408, Val loss 0.983\n",
            "Ep 2 (Step 001580): Train loss 0.665, Val loss 0.989\n",
            "Ep 2 (Step 001585): Train loss 0.421, Val loss 0.988\n",
            "Ep 2 (Step 001590): Train loss 0.454, Val loss 0.989\n",
            "Ep 2 (Step 001595): Train loss 0.926, Val loss 0.987\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Answer the question based on the context provided below. \"Please provide the specific number of ACC opponents that the Fighting Irish are scheduled to play against in a typical season.\"  ### Input: Notre Dame's conference affiliations for all of its sports except football and fencing changed in July 2013 as a result of major conference realignment, and its fencing affiliation will change in July 2014. The Irish left the Big East for the ACC during a prolonged period of instability in the Big East; while they maintain their football independence, they have committed to play five games per season against ACC opponents. In ice hockey, the Irish were forced to find a new conference home after the Big Ten Conference's decision to add the sport in 2013–14 led to a cascade of conference moves that culminated in the dissolution of the school's former hockey home, the Central Collegiate Hockey Association, after the 2012–13 season. Notre Dame moved its hockey team to Hockey East. After Notre Dame joined the ACC, the conference announced it would add fencing as a sponsored sport beginning in the 2014–15 school year. There are many theories behind the adoption of the athletics moniker but it is known that the Fighting Irish name was used in the early 1920s with respect to the football team and was popularized by alumnus Francis Wallace in his New York Daily News columns. The official colors of Notre Dame are Navy Blue and Gold Rush which are worn in competition by its athletic teams. In addition, the color green is often worn because of the Fighting Irish nickname. The Notre Dame Leprechaun is the mascot of the athletic teams. Created by Theodore W. Drake in 1964, the leprechaun was first used on the football pocket schedule and later on the football program covers. The leprechaun was featured on the cover of Time in November 1964 and gained national exposure.  ### Response: five games per season  ### Response: five games per season<|endoftext|>The following blog post, unless otherwise noted, was written by a member of Gamasutra's community.  The thoughts and opinions expressed are those of the writer and not Gam\n",
            "Training completed in 16.91 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plot losses"
      ],
      "metadata": {
        "id": "nHNALimXBjIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "i5oOT_cgBiP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "46c5de2b-329a-41b1-85d6-d43bb5174fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate Response"
      ],
      "metadata": {
        "id": "K2uxqvP3FMvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ],
      "metadata": {
        "id": "agnW00DSFLOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ea98ef-b192-4efc-9909-a64132fa9bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Answer the question based on the context provided below. \"Provide information regarding the nature of the institution known as the University of Notre Dame.\"\n",
            "\n",
            "### Input:\n",
            "The University of Notre Dame du Lac (or simply Notre Dame /ˌnoʊtərˈdeɪm/ NOH-tər-DAYM) is a Catholic research university located adjacent to South Bend, Indiana, in the United States. In French, Notre Dame du Lac means \"Our Lady of the Lake\" and refers to the university's patron saint, the Virgin Mary. The main campus covers 1,250 acres in a suburban setting and it contains a number of recognizable landmarks, such as the Golden Dome, the \"Word of Life\" mural (commonly known as Touchdown Jesus), and the Basilica.\n",
            "\n",
            "### Response:\n",
            "Catholic research university\n",
            "\n",
            "Correct response:\n",
            ">> Catholic research university\n",
            "\n",
            "Model response:\n",
            ">> Catholic research university\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Answer the question based on the context provided below. \"Please identify the organization that bestowed the distinction of being 'outstanding' upon the First Year of Studies program at Notre Dame.\"\n",
            "\n",
            "### Input:\n",
            "All of Notre Dame's undergraduate students are a part of one of the five undergraduate colleges at the school or are in the First Year of Studies program. The First Year of Studies program was established in 1962 to guide incoming freshmen in their first year at the school before they have declared a major. Each student is given an academic advisor from the program who helps them to choose classes that give them exposure to any major in which they are interested. The program also includes a Learning Resource Center which provides time management, collaborative learning, and subject tutoring. This program has been recognized previously, by U.S. News & World Report, as outstanding.\n",
            "\n",
            "### Response:\n",
            "U.S. News & World Report\n",
            "\n",
            "Correct response:\n",
            ">> U.S. News & World Report\n",
            "\n",
            "Model response:\n",
            ">> U.S. News & World Report\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "\"Please distill the main ideas and crucial information from the provided news article into a concise overview, highlighting essential facts and key takeaways.\"\n",
            "\n",
            "### Input:\n",
            "WASHINGTON (CNN) -- With the election of the next president a year away, Sen. Hillary Clinton remains the person to beat, a CNN/Opinion Research Corporation poll released Monday suggests. As the countdown begins to November 4, 2008, the New York Democrat continues to dominate the race for the Democratic presidential nomination, and comes out ahead when voters are asked whether they prefer her or the GOP front-runner, former New York Mayor Rudy Giuliani. But Clinton's path to the White House is in no way certain. Clinton was criticized for her performance during a debate last week, and her rivals for the Democratic nomination have stepped up attacks that she has equivocated on her position on Iraq, Iran and other major issues. The Republican presidential candidates have also stepped up their attacks on the Democratic front-runner, with each suggesting that he has the best chance of stopping Clinton. The attacks may be working. The CNN/Opinion Research polls suggests that Clinton's support has slipped from its height one month ago.  Watch CNN's Bill Schneider on the latest poll numbers » . \"Clinton's strength is about where it was throughout the summer, indicating that she has lost the support she gained last month but that Obama has not yet cut into her core constituency,\" CNN political director Keating Holland said. Clinton is the top choice of 44 percent of the likely Democratic voters interviewed for the poll. Her closest rival, Sen. Barack Obama of Illinois, was the top choice of 25 percent, and former Sen. John Edwards of North Carolina has 14 percent. All other Democratic candidates were in single digits. New Mexico Gov. Bill Richardson was backed by 4 percent, Sen. Joe Biden of Delaware by 3 percent, Sen. Christopher Dodd by 2 percent, Ohio Rep. Dennis Kucinich by 2 percent and former Alaska Sen. Mike Gravel was at 1 percent. The poll involved 467 interviews conducted on November 2-4 with Democrats or independents who lean Democratic. The poll's margin of error was plus or minus 4.5 percentage points.  View the poll results » . In an October CNN/Opinion Research poll, Clinton was supported by 51 percent of Democratic voters and had a 30 point lead over Obama. During last week's Democratic debate, Clinton received heavy criticism from her fellow Democratic presidential rivals, who are desperate to shake up the presidential race just months before the first voting occurs in the Iowa Caucus in early January. Edwards was particularly aggressive during the debate, criticizing Clinton for her stance on Iraq, Iran and Social Security. \"The American people ... deserve a president of the United States that they know will tell them the truth and won't say one thing one time and something different at a different time,\" Edwards said. Edwards has also accused Clinton of being a \"corporate Democrat\" too willing to defend a \"corrupt\" Washington establishement. \"We desperately need in the next president someone that recognizes we have a system in Washington that's become broken, corruption has crept into it, and we have to tell the truth about that,\" Edwards said Monday. \"If you defend that system, I don't believe you can bring about the change that America needs.\" In the Republican presidential race, Giuliani continues to be the leading candidate, with the backing of 28 percent of the Republican primary voters polled. Former Sen. Fred Thompson of Tennessee was backed by 19 percent. Sen. John McCain of Arizona was the top pick of 16 percent, and former Massachusetts Gov. Mitt Romney had 11 percent. Of the remaining Republican candidates, former Arkansas Gov. Mike Huckabee received 10 percent, Texas Rep. Ron Paul 5 percent, California Rep. Duncan Hunter 4 percent and Colorado Rep. Tom Tancredo 3 percent. The poll involved telephone interviews with 397 Republicans or independents who lean Republican. The poll's margin of error was 5 percentage points. In a head-to-head matchup of the two front-runners, Clinton leads Giuliani 51 percent to 45 percent. That lead has increased since October, when Clinton led Giuliani 49 percent to 47 percent. \"The overall political environment seems to favor the Democrats, partly because Democratic voters are more enthusiastic about the coming election and partly because the public is in a sour mood, which is usually not a good sign for the incumbent party,\" Holland said. Only 42 percent of Americans think things are going well, while 58 percent think things are going badly, the poll found. \"The public is not just pessimistic about the country -- Americans are angry,\" Holland said.  \"More than eight in 10 say they are angry about the way things are going in the country.\" Clinton's lead over Giuliani would be greater if a third-party candidate entered the race who believes abortion should be illegal in all circumstances, the poll found. In a three-way race, Clinton would get the support of 48 percent of voters, Giuliani 32 percent and the third-party candidate 18 percent. The poll's margin of error was plus-or-minus 3 percent. \"My analysis of it is that [a third-party candidate] is more of an attempt to keep the nomination from me,\" Giuliani said. \"You know it is a tactic, and a legitimate one. People have to think about that and consider it.'' The lack of enthusiasm for Giuliani, particularly by social conservatives, could spell trouble for the GOP next year if he becomes the nominee, Holland said. \"Only 27 percent of Republicans say they would feel enthusiastic if Giuliani won the GOP nod, and the remaining GOP candidates fare even worse,\" he said. E-mail to a friend .\n",
            "\n",
            "### Response:\n",
            "Sen. Clinton supported by 44 percent of Democrats polled, down from October .\n",
            "Rudy Giuliani continues to lead Republican presidential field with 28 percent .\n",
            "Clinton beats Giuliani 51 percent to 45 percent, the poll found .\n",
            "Only 42 percent think things are going well in the U.S., according to the poll .\n",
            "\n",
            "Correct response:\n",
            ">> Sen. Clinton supported by 44 percent of Democrats polled, down from October .\n",
            "Rudy Giuliani continues to lead Republican presidential field with 28 percent .\n",
            "Clinton beats Giuliani 51 percent to 45 percent, the poll found .\n",
            "Only 42 percent think things are going well in the U.S., according to the poll .\n",
            "\n",
            "Model response:\n",
            ">> Sen. Clinton supported by 44 percent of Democrats polled, down from October .\n",
            "Rudy Giuliani continues to lead Republican presidential field with 28 percent .\n",
            "Clinton beats Giuliani 51 percent to 45 percent, the poll found .\n",
            "Only 42 percent think things are going well in the U.S., according to the poll .\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving Test Data Responses"
      ],
      "metadata": {
        "id": "VLxZRi98GywR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response2.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing\n",
        "files.download(\"instruction-data-with-response2.json\")"
      ],
      "metadata": {
        "id": "I3f8s5d6GyP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b9e20b1-99ef-4f95-8c0d-c31b309ea3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [09:38<00:00,  5.79s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d1727f50-3ec5-4b31-ac9c-63bc6cae7cf6\", \"instruction-data-with-response2.json\", 180603)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_diferentes = [id for id in test_data if id['model_response'] != id['output']]\n",
        "len(ids_diferentes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8hKxfu9y6UH",
        "outputId": "4fbd96e7-a51e-4ad6-802f-51a3926f45b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving Model"
      ],
      "metadata": {
        "id": "8MyVtlEfHLyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n"
      ],
      "metadata": {
        "id": "IXaB6wR3HM53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b48b14-0e73-4727-c03f-7611c029360b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    }
  ]
}